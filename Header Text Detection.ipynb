{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34184be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74a28f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_document(path):\n",
    "    \"\"\"Detects document features in an image.\"\"\"\n",
    "    from google.cloud import vision\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    # Specify language as English\n",
    "    image_context = vision.ImageContext(language_hints=[\"en\"])\n",
    "\n",
    "    response = client.document_text_detection(image=image, image_context=image_context)\n",
    "\n",
    "    for page in response.full_text_annotation.pages:\n",
    "        for block in page.blocks:\n",
    "            print(f\"\\nBlock confidence: {block.confidence}\\n\")\n",
    "\n",
    "            for paragraph in block.paragraphs:\n",
    "                print(\"Paragraph confidence: {}\".format(paragraph.confidence))\n",
    "\n",
    "                for word in paragraph.words:\n",
    "                    word_text = \"\".join([symbol.text for symbol in word.symbols])\n",
    "                    print(\n",
    "                        \"Word text: {} (confidence: {})\".format(\n",
    "                            word_text, word.confidence\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                    for symbol in word.symbols:\n",
    "                        print(\n",
    "                            \"\\tSymbol: {} (confidence: {})\".format(\n",
    "                                symbol.text, symbol.confidence\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "    \n",
    "    return response.full_text_annotation.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4271f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Block confidence: 0.8273344039916992\n",
      "\n",
      "Paragraph confidence: 0.8273344039916992\n",
      "Word text: Furst (confidence: 0.8869720101356506)\n",
      "\tSymbol: F (confidence: 0.7302184104919434)\n",
      "\tSymbol: u (confidence: 0.798406183719635)\n",
      "\tSymbol: r (confidence: 0.9474553465843201)\n",
      "\tSymbol: s (confidence: 0.9712465405464172)\n",
      "\tSymbol: t (confidence: 0.9875335097312927)\n",
      "Word text: Door (confidence: 0.7933574914932251)\n",
      "\tSymbol: D (confidence: 0.5096052289009094)\n",
      "\tSymbol: o (confidence: 0.903228759765625)\n",
      "\tSymbol: o (confidence: 0.8595099449157715)\n",
      "\tSymbol: r (confidence: 0.901086151599884)\n",
      "Word text: Rite (confidence: 0.7867642641067505)\n",
      "\tSymbol: R (confidence: 0.6802905201911926)\n",
      "\tSymbol: i (confidence: 0.5332353115081787)\n",
      "\tSymbol: t (confidence: 0.9713659286499023)\n",
      "\tSymbol: e (confidence: 0.9621654152870178)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Furst Door Rite'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_document(\"data/form_info_001/apartment_no/02110.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48208e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Block confidence: 0.9626752734184265\n",
      "\n",
      "Paragraph confidence: 0.9626752734184265\n",
      "Word text: 244-246 (confidence: 0.9626752734184265)\n",
      "\tSymbol: 2 (confidence: 0.954619824886322)\n",
      "\tSymbol: 4 (confidence: 0.9492464661598206)\n",
      "\tSymbol: 4 (confidence: 0.9696445465087891)\n",
      "\tSymbol: - (confidence: 0.9245619773864746)\n",
      "\tSymbol: 2 (confidence: 0.9778190851211548)\n",
      "\tSymbol: 4 (confidence: 0.9862685203552246)\n",
      "\tSymbol: 6 (confidence: 0.9765665531158447)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'244-246'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_document(\"data/form_info_001/street_no/02112.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b56ec40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Block confidence: 0.8680002093315125\n",
      "\n",
      "Paragraph confidence: 0.8680002093315125\n",
      "Word text: 2 (confidence: 0.8680002093315125)\n",
      "\tSymbol: 2 (confidence: 0.8680002093315125)\n",
      "\n",
      "Block confidence: 0.6058118343353271\n",
      "\n",
      "Paragraph confidence: 0.6058118343353271\n",
      "Word text: trand (confidence: 0.6058118343353271)\n",
      "\tSymbol: t (confidence: 0.3441177010536194)\n",
      "\tSymbol: r (confidence: 0.44613581895828247)\n",
      "\tSymbol: a (confidence: 0.745262861251831)\n",
      "\tSymbol: n (confidence: 0.6531288623809814)\n",
      "\tSymbol: d (confidence: 0.8404139280319214)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'grand'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import difflib\n",
    "\n",
    "def best_match(text, options):\n",
    "    \"\"\"\n",
    "    Find the best match for a given text from a list of options.\n",
    "\n",
    "    :param text: The text to match.\n",
    "    :param options: A list of possible options to match against.\n",
    "    :return: The option that best matches the text.\n",
    "    \"\"\"\n",
    "    return difflib.get_close_matches(text, options, n=1, cutoff=0.0)[0]\n",
    "\n",
    "# Example usage\n",
    "\n",
    "text = detect_document(\"data/form_info_001/street/02112.jpg\")\n",
    "text = text.lower()\n",
    "options = [\"flower\", \"clay\", \"grand\", \"figueroa\", \"bunker hill ave\", \"cinnabar\", \"hope\", \"west\"]\n",
    "best_match_result = best_match(text, options)\n",
    "best_match_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61e69076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02725.jpg\n",
      "00132.jpg\n",
      "00654.jpg\n",
      "02043.jpg\n",
      "02057.jpg\n",
      "00640.jpg\n",
      "00898.jpg\n",
      "01238.jpg\n",
      "00126.jpg\n",
      "02731.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import difflib\n",
    "from google.cloud import vision\n",
    "\n",
    "def detect_document(path):\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    with open(path, \"rb\") as image_file:\n",
    "        content = image_file.read()\n",
    "    image = vision.Image(content=content)\n",
    "    image_context = vision.ImageContext(language_hints=[\"en\"])\n",
    "    response = client.document_text_detection(image=image, image_context=image_context)\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            \"{}\\nFor more info on error messages, check: \"\n",
    "            \"https://cloud.google.com/apis/design/errors\".format(response.error.message)\n",
    "        )\n",
    "    return response.full_text_annotation.text\n",
    "\n",
    "def best_match(text, options):\n",
    "    return difflib.get_close_matches(text, options, n=1, cutoff=0.0)[0]\n",
    "\n",
    "def process_images_sync():\n",
    "    base_path = \"data/form_info_001\"\n",
    "    directories = [\"street\", \"street_no\", \"apartment_no\"]\n",
    "    street_options = [\"flower\", \"clay\", \"grand\", \"figueroa\", \"bunker hill ave\", \"cinnabar\", \"hope\", \"west\"]\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for index in os.listdir(os.path.join(base_path, directories[0]))[:10]:\n",
    "        print(index)\n",
    "        if not index.endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
    "            continue\n",
    "        record = {'index': index}\n",
    "        for dir in directories:\n",
    "            image_path = os.path.join(base_path, dir, index)\n",
    "            text = detect_document(image_path).lower()\n",
    "            if dir == \"street\":\n",
    "                text = best_match(text, street_options)\n",
    "            record[dir] = text\n",
    "        data.append(record)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df = process_images_sync()\n",
    "df.set_index('index', inplace=True)\n",
    "df.to_csv(\"processed_text_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b814702",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/v0/dlhfhpj533b4_ldsv6gq0q8h0000gn/T/ipykernel_32017/313871592.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"processed_text_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.10/lib/python3.8/asyncio/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \"\"\"\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m     34\u001b[0m             \"asyncio.run() cannot be called from a running event loop\")\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "def process_image(index, directories, street_options, base_path):\n",
    "    record = {'index': index}\n",
    "    for dir in directories:\n",
    "        image_path = os.path.join(base_path, dir, index)\n",
    "        text = detect_document(image_path).lower()\n",
    "        if dir == \"street\":\n",
    "            text = best_match(text, street_options)\n",
    "        record[dir] = text\n",
    "    return record\n",
    "\n",
    "def process_images_concurrently():\n",
    "    base_path = \"data/form_info_001\"\n",
    "    directories = [\"street\", \"street_no\", \"apartment_no\"]\n",
    "    street_options = [\"flower\", \"clay\", \"grand\", \"figueroa\", \"bunker hill ave\", \"cinnabar\", \"hope\", \"west\"]\n",
    "\n",
    "    all_files = os.listdir(os.path.join(base_path, directories[0]))[:1000]\n",
    "    assert len(all_files) < 11\n",
    "    data = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=32) as executor:\n",
    "        future_to_file = {executor.submit(process_image, file, directories, street_options, base_path): file for file in all_files}\n",
    "        for future in concurrent.futures.as_completed(future_to_file):\n",
    "            data.append(future.result())\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df = process_images_concurrently()\n",
    "df.set_index('index', inplace=True)\n",
    "df.to_csv(\"processed_text_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f960c1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
